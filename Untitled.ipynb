{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import skimage.filters\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import PIL\n",
    "from skimage import io\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gblur_level = np.linspace(9, 200, num=10)\n",
    "def generate_blur_img(level, image, image_num):\n",
    "    hsize = gblur_level[level]\n",
    "#         distorted_img = cv2.GaussianBlur(image,(hsize,hsize),cv2.BORDER_DEFAULT)\n",
    "    hsize = int(hsize)\n",
    "    if hsize % 2 == 0:\n",
    "        hsize += 1\n",
    "#     print(hsize)\n",
    "    distorted_img = cv2.GaussianBlur(image,(hsize,hsize),cv2.BORDER_DEFAULT)\n",
    "    im = PIL.Image.fromarray(distorted_img)\n",
    "    if image_num < 10:\n",
    "        image_num = f'0{image_num}'\n",
    "    else:\n",
    "        image_num = f'{image_num}'\n",
    "    if level < 10:\n",
    "        level = f'0{level}'\n",
    "    else:\n",
    "        level = f'{level}'\n",
    "    \n",
    "    tmp_path = f'/Users/metis_sotangkur/Desktop/Senior/Capstone/distorted_img/{image_num}_{level}.jpg'\n",
    "    im.save(tmp_path,\"JPEG\")\n",
    "\n",
    "img_pth_list = [\n",
    "    '/Users/metis_sotangkur/Desktop/Senior/Capstone/Example_images/14_Actinic_Keratosis/case02/03.JPG',\\\n",
    "    '/Users/metis_sotangkur/Desktop/Senior/Capstone/Example_images/14_Actinic_Keratosis/case03/03.JPG',\\\n",
    "    '/Users/metis_sotangkur/Desktop/Senior/Capstone/Example_images/14_Actinic_Keratosis/case03/07.JPG',\\\n",
    "    '/Users/metis_sotangkur/Desktop/Senior/Capstone/Example_images/14_Actinic_Keratosis/case04/03.JPG',\\\n",
    "    '/Users/metis_sotangkur/Desktop/Senior/Capstone/Example_images/14_Actinic_Keratosis/case05/04.JPG',\\\n",
    "    '/Users/metis_sotangkur/Desktop/Senior/Capstone/Example_images/14_Actinic_Keratosis/case06/03.JPG',\\\n",
    "    '/Users/metis_sotangkur/Desktop/Senior/Capstone/Example_images/01_Melanoma/19.JPG',\\\n",
    "    '/Users/metis_sotangkur/Desktop/Senior/Capstone/Example_images/01_Melanoma/20.JPG',\\\n",
    "    '/Users/metis_sotangkur/Desktop/Senior/Capstone/Example_images/01_Melanoma/24.JPG',\\\n",
    "    '/Users/metis_sotangkur/Desktop/Senior/Capstone/Example_images/01_Melanoma/23.JPG',\\\n",
    "    '/Users/metis_sotangkur/Desktop/Senior/Capstone/Example_images/01_Melanoma/26.JPG',\\\n",
    "    '/Users/metis_sotangkur/Desktop/Senior/Capstone/Example_images/01_Melanoma/27.JPG',\\\n",
    "#     '/Users/metis_sotangkur/Desktop/Senior/Capstone/Example_images/02_basal_cell_carcinoma/Basal_cell_epithelioma_Basal_cell\\ carcinoma_of_skin/case02/03.JPG'\n",
    "]\n",
    "\n",
    "\n",
    "for idx, path in enumerate(img_pth_list):\n",
    "    image = io.imread(path)\n",
    "    for level in range(10):\n",
    "        generate_blur_img(level, image, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Image' object has no attribute 'unsqueeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-0f08fd3263a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistorted_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_img_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mimg_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Senior/Capstone/compact_bilinear_pooling_cnn/predict_util.py\u001b[0m in \u001b[0;36mpredict_img_2\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_skin_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Image' object has no attribute 'unsqueeze'"
     ]
    }
   ],
   "source": [
    "from predict_util import *\n",
    "import urllib.request\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "response = urllib.request.urlopen('https://www.python.org')\n",
    "# print(response.read().decode('utf-8'))\n",
    "S_CNN_PATH = 'revised_model_13_10_2021_0.pth'\n",
    "MODEL_PATH = 'db_cnn_v2_challenge.pth'\n",
    "Predict = PREDICT_UTIL(model_path = MODEL_PATH, s_cnn_path=S_CNN_PATH)\n",
    "Predict.load_model()\n",
    "\n",
    "\n",
    "distorted_path = '/Users/metis_sotangkur/Desktop/Senior/Capstone/distorted_img/'\n",
    "img_score = []\n",
    "for image_num in range(12):\n",
    "    tmp = []\n",
    "    for level in range(10):\n",
    "        if image_num < 10:\n",
    "            image_num = f'0{image_num}'\n",
    "        else:\n",
    "            image_num = f'{image_num}'\n",
    "        if level < 10:\n",
    "            level = f'0{level}'\n",
    "        else:\n",
    "            level = f'{level}'\n",
    "        img_name = f'{image_num}_{level}.jpg'\n",
    "        img_path = distorted_path + img_name\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        score = Predict.predict_img_2(image)\n",
    "        tmp.append(score)\n",
    "    img_score.append(tmp)\n",
    "print(img_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
